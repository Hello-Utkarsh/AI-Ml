# ğŸ“ What is a Vector?

Vectors are fundamental to understanding concepts in **physics**, **mathematics**, and **computer science** â€” and each field brings its own perspective:

- **According to Physics**:  
  A vector is an **arrow** pointing in space with a specific **length** (magnitude) and **direction**.

- **According to Computer Science**:  
  A vector is an **ordered list of numbers**, often used in programming and data structures.

- **According to Mathematics**:  
  A vector is a **quantity that has both magnitude and direction**, and is usually represented as an **ordered tuple of numbers** in a coordinate system â€” combining the intuition from both physics and computer science.

---

## ğŸ§­ What Does a Vector Even Look Like?

> _â€œA vector starts at the origin and points to a location in space.â€_

![Vector Example](./assets/Vector%20Exp.png)

The values in a vector tell us how far and in which direction we move from the origin:

- In a 2D vector like `[3, 4]`,  
  - `3` â†’ movement along the **x-axis**  
  - `4` â†’ movement along the **y-axis**
- In a 3D vector like `[3, 4, 5]`,  
  - `5` â†’ movement along the **z-axis**

Itâ€™s like a set of instructions:  
> "Go 3 units to the right, then 4 units up" Youâ€™ve moved to the point `(3, 4)`.

---

## ğŸ¯ Basis / Unit Vectors

**Basis vectors** are special vectors that:
- Have a **magnitude of 1**
- Represent the **direction** of each axis

They are usually written as:
- `iÌ‚` â†’ unit vector in the **x-direction**
- `jÌ‚` â†’ unit vector in the **y-direction**
- `kÌ‚` â†’ unit vector in the **z-direction**

---

## ğŸŒŒ Span

The **span** of a set of vectors is the collection of all points you can reach using them (by scaling and adding).

- Using `iÌ‚` and `jÌ‚`, you can reach any point on a 2D plane â†’ the span is **2D**
- Using `iÌ‚`, `jÌ‚`, and `kÌ‚`, you can reach any point in 3D space â†’ the span is **3D**

---

## ğŸ“š Types of Vectors

### 1. Linearly Dependent Vectors
These vectors **donâ€™t add a new direction**. They are just scalar multiples of each other and lie on the same line or axis.

> Example: `3iÌ‚` and `5iÌ‚` both lie on the x-axis. One is just a longer/shorter version of the other, but no new direction is introduced.

---

### 2. Linearly Independent Vectors
These vectors **introduce new directions** or dimensions.

> Example: `3iÌ‚` and `5jÌ‚` are linearly independent because `iÌ‚` lies on the x-axis and `jÌ‚` lies on the y-axis â€” two different directions.

---

## â•âœ–ï¸ How Do We Add or Multiply Vectors?

### â• **Vector Addition**

Adding vectors is just like adding numbers **axis-wise**:

[3, 4] + [5, -2] = [3 + 5, 4 + (-2)] = [8, 2]


![Vector Example](./assets/Vector%20Addition1.png)

![Vector Example](./assets/Vector%20Addition2.png)


**Visual Interpretation**:  
- Go `3m` east and `4m` north â†’ `[3, 4]`
- Then go `5m` east and `2m` south â†’ `[5, -2]`  
- Final position: `8m` east, `2m` north â†’ `[8, 2]`

### âœ–ï¸ **Vector Multiplication**

There are two main types:

#### 1. **Scalar Multiplication**

Multiply each element of the vector by a scalar (just a number):

3 Ã— [1, 2] = [3, 6]


**In physics terms**:  
Going `1m` east and `2m` north, 3 times in a row, lands you at `3m` east and `6m` north.

---

## ğŸ“ What is Linear Transformation?

A **linear transformation** is a function that takes vectors as input and transforms them into new vectors, while preserving two key properties:

1. The **origin stays fixed** (no shifting).
2. **Grid lines remain straight and parallel** (lines stay straight and equally spaced).

Think of it as changing the _rulers_ (basis vectors) you use to measure space, not the space itself.

---

### ğŸ§  Example:

Letâ€™s say you have a vector:

v = [2, 3]


In the **default grid**, this means:
- Move **2 units along the x-axis** â†’ using the standard basis `[1, 0]`
- Move **3 units along the y-axis** â†’ using the standard basis `[0, 1]`

Now, apply a **linear transformation** that changes the basis vectors:

- New x-axis basis vector â†’ `i' = [1, -1]`
- New y-axis basis vector â†’ `j' = [1, 1]`

So instead of building the vector using `[1, 0]` and `[0, 1]`, we now use the new basis:

v' = 2 Ã— [1, -1] + 3 Ã— [1, 1] = [2, -2] + [3, 3] = [5, 1]


This means the vector `[2, 3]` is **mapped to** `[5, 1]` under the new grid.

![Vector Transformation](./assets/Vector%20Transformation.png)

In short: Linear transformations **reshape the grid**, not the space. They give you a new way to describe and work with vectors!

---

## ğŸŒ€ Matrix Composition

In linear algebra, transformation matrices can rotate, scale, shear, or reflect vectors. When you apply transformations multiple times, you can **compose** them using matrix multiplication.

## 2D Matrix

### ğŸ” One 90Â° Rotation

The transformation matrix for a **90Â° counterclockwise rotation** is:

R = [ [ 0, -1 ], [ 1, 0 ] ]


### ğŸ”ğŸ” Two 90Â° Rotations (180Â° Total)

To rotate a vector 90Â° **twice**, you multiply the rotation matrix by itself:

R Ã— R = [ [ 0, -1 ], [ [ 0, -1 ], [ 1, 0 ] ] Ã— [ 1, 0 ] ]

  = [ [-1,  0 ],
     [ 0, -1 ] ]


This result is the matrix for a **180Â° rotation**, which flips both x and y directions.

### âœ… Conclusion

Matrix multiplication lets us **combine transformations**:

- One 90Â° rotation â `R`
- Two 90Â° rotations â `R Ã— R = 180Â° rotation`
- And so on...

By composing matrices, we can stack multiple linear transformations together into one!

## ğŸ”„ Order of Transformations Matters!

When composing transformations using **matrix multiplication**, the **order** in which you multiply them affects the result.

Matrix multiplication is **not commutative**, which means:

A Ã— B â‰  B Ã— A

Letâ€™s say:
- `R` is a **rotation matrix**
- `S` is a **shear matrix**

If you rotate then shear:
Final = S Ã— R (First apply R, then S)

If you shear then rotate:
Final = R Ã— S (First apply S, then R)

These will generally give **different results**, because the transformation is applied **in sequence**, and each one changes the coordinate system for the next.

### âœ… Exception: Same Matrices

In our previous example:
R =  [[ 0, -1 ], [ 1, 0 ] ]

We applied the same rotation matrix twice:
R Ã— R = RÂ² = 180Â° rotation

Since both matrices were the same, the order didnâ€™t matter **in this special case**. But in general, **always be mindful of the order** when combining transformations!

---

# ğŸ“ Determinants â€“ Explained Simply

A determinant is a scalar value that can be computed from a square matrix. It gives insight into the transformation properties of a matrixâ€”especially area/volume scaling, invertibility, and orientation (flipping).

---

## ğŸ”· 2D Determinant

Given a 2Ã—2 matrix:

| a b | | c d |


The **determinant** is:
det = ad - bc


### What it means:
- `det = 1`: Area unchanged
- `det = 2`: Area doubled
- `det = 0`: Collapsed into a line (not invertible)
- `det < -2`: Flipped across an axis (mirrored) and scaled 2 times

### Example:

Matrix:
| 2 1 | | 1 1 |
det = 2Ã—1 - 1Ã—1 = 1


âœ… Area stays the same, but the shape gets sheared.

---

## ğŸ”· 3D Determinant

In 3D, the determinant of a 3Ã—3 matrix gives the volume scaling factor of a parallelepiped formed by three vectors.

Given a 3Ã—3 matrix:
A = | a1  a2  a3 |
    | b1  b2  b3 |
    | c1  c2  c3 |

det(A) = a1(b2c3 - b3c2) - a2(b1c3 - b3c1) + a3(b1c2 - b2c1)

### Example:
| 1 0 0 | | 0 2 0 | | 0 0 3 |
det = 1 Ã— 2 Ã— 3 = 6